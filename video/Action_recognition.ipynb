{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Action recognition.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOYrRRw12Bjn9qRPoC8VNSv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ee8cf44aa4d041009158b4922c3efd04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fe50dc0e27d64b568eadcf99b0228705",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9bb66e4932394e56b5ee8103cea4bbc9",
              "IPY_MODEL_98c41a17ff614f378114240557f888f5"
            ]
          }
        },
        "fe50dc0e27d64b568eadcf99b0228705": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9bb66e4932394e56b5ee8103cea4bbc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a5fcaa3f345542f6a01e8f4d8c41bdc4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 133546016,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 133546016,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_20c9c890682d407094cd290df9fd6e8a"
          }
        },
        "98c41a17ff614f378114240557f888f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b4a1b57c8d5441adabbdc832f66fe6b6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 127M/127M [00:03&lt;00:00, 37.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2b272961ba6c4d90ae3bea035df4546f"
          }
        },
        "a5fcaa3f345542f6a01e8f4d8c41bdc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "20c9c890682d407094cd290df9fd6e8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b4a1b57c8d5441adabbdc832f66fe6b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2b272961ba6c4d90ae3bea035df4546f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gan4x4/CV-HSE2019/blob/master/video/Action_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t37vDPI1AYct",
        "colab_type": "code",
        "outputId": "217c219d-a63f-4691-c7a0-e745b83c90e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "# Download labels for Keenetic - 400\n",
        "!wget https://gist.githubusercontent.com/willprice/f19da185c9c5f32847134b87c1960769/raw/9dc94028ecced572f302225c49fcdee2f3d748d8/kinetics_400_labels.csv -O kinetics_400_labels.csv\n",
        "\n",
        "# Download youtube-dl\n",
        "!sudo wget https://yt-dl.org/downloads/latest/youtube-dl\n",
        "\n",
        "# Make youtube-dl executable\n",
        "!sudo chmod a+rx youtube-dl\n",
        "\n",
        "# Download \"Scent of a woman\" trailer\n",
        "! ./youtube-dl -f 134 https://www.youtube.com/watch?v=losLAzU9YCk -o video.mp4"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-16 13:43:35--  https://gist.githubusercontent.com/willprice/f19da185c9c5f32847134b87c1960769/raw/9dc94028ecced572f302225c49fcdee2f3d748d8/kinetics_400_labels.csv\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7454 (7.3K) [text/plain]\n",
            "Saving to: ‘kinetics_400_labels.csv’\n",
            "\n",
            "\rkinetics_400_labels   0%[                    ]       0  --.-KB/s               \rkinetics_400_labels 100%[===================>]   7.28K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-03-16 13:43:35 (47.6 MB/s) - ‘kinetics_400_labels.csv’ saved [7454/7454]\n",
            "\n",
            "--2020-03-16 13:43:37--  https://yt-dl.org/downloads/latest/youtube-dl\n",
            "Resolving yt-dl.org (yt-dl.org)... 95.143.172.170, 2001:1a50:11:0:5f:8f:acaa:177\n",
            "Connecting to yt-dl.org (yt-dl.org)|95.143.172.170|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://yt-dl.org/downloads/2020.03.08/youtube-dl [following]\n",
            "--2020-03-16 13:43:38--  https://yt-dl.org/downloads/2020.03.08/youtube-dl\n",
            "Connecting to yt-dl.org (yt-dl.org)|95.143.172.170|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/ytdl-org/youtube-dl/releases/download/2020.03.08/youtube-dl [following]\n",
            "--2020-03-16 13:43:38--  https://github.com/ytdl-org/youtube-dl/releases/download/2020.03.08/youtube-dl\n",
            "Resolving github.com (github.com)... 140.82.118.4\n",
            "Connecting to github.com (github.com)|140.82.118.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/1039520/d703ce80-616a-11ea-827d-66c5b8593ce6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200316%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200316T134138Z&X-Amz-Expires=300&X-Amz-Signature=ddfc4d14eb56c62687c81dd104eae64918a595931cd9bb292155e2e4a8d29dd4&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dyoutube-dl&response-content-type=application%2Foctet-stream [following]\n",
            "--2020-03-16 13:43:38--  https://github-production-release-asset-2e65be.s3.amazonaws.com/1039520/d703ce80-616a-11ea-827d-66c5b8593ce6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200316%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200316T134138Z&X-Amz-Expires=300&X-Amz-Signature=ddfc4d14eb56c62687c81dd104eae64918a595931cd9bb292155e2e4a8d29dd4&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dyoutube-dl&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.217.47.84\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.217.47.84|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1750043 (1.7M) [application/octet-stream]\n",
            "Saving to: ‘youtube-dl’\n",
            "\n",
            "youtube-dl          100%[===================>]   1.67M  3.38MB/s    in 0.5s    \n",
            "\n",
            "2020-03-16 13:43:39 (3.38 MB/s) - ‘youtube-dl’ saved [1750043/1750043]\n",
            "\n",
            "[youtube] losLAzU9YCk: Downloading webpage\n",
            "[download] Destination: video.mp4\n",
            "\u001b[K[download] 100% of 3.79MiB in 00:00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-_mN7JPF-EC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "# Read labels from Keenetic - 400 dataset\n",
        "# becouse PyTorch models trained on it\n",
        "\n",
        "def read_labels():\n",
        "    labels = {}\n",
        "    with open('kinetics_400_labels.csv', newline='') as csvfile:\n",
        "        reader = csv.reader(csvfile, delimiter=',')\n",
        "        i = 0\n",
        "        for col in reader:\n",
        "            if i == 0:\n",
        "                print(';'.join(col))\n",
        "            else:\n",
        "                labels[int(col[0])] = col[1]\n",
        "            i += 1\n",
        "    return labels\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdH_r7lGzklM",
        "colab_type": "code",
        "outputId": "bfb36ab2-400d-4f08-d981-9c5185ce2284",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        }
      },
      "source": [
        "# Not worked :(\n",
        "import torchvision\n",
        "fragment = torchvision.io.read_video(\"video.mp4\", 0, 64, pts_unit='pts')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-c5d27b8a2e1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfragment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"video.mp4\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpts_unit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pts'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/io/video.py\u001b[0m in \u001b[0;36mread_video\u001b[0;34m(filename, start_pts, end_pts, pts_unit)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_video_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_pts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_pts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpts_unit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m     \u001b[0m_check_av_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mend_pts\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/io/video.py\u001b[0m in \u001b[0;36m_check_av_available\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_check_av_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mav\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mav\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: PyAV is not installed, and is necessary for the video operations in torchvision.\nSee https://github.com/mikeboers/PyAV#installation for instructions on how to\ninstall PyAV on your system.\n",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HQg6N_s6EwQ",
        "colab_type": "code",
        "outputId": "d0216eff-4e13-4c8f-b52c-4862e5077af7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ee8cf44aa4d041009158b4922c3efd04",
            "fe50dc0e27d64b568eadcf99b0228705",
            "9bb66e4932394e56b5ee8103cea4bbc9",
            "98c41a17ff614f378114240557f888f5",
            "a5fcaa3f345542f6a01e8f4d8c41bdc4",
            "20c9c890682d407094cd290df9fd6e8a",
            "b4a1b57c8d5441adabbdc832f66fe6b6",
            "2b272961ba6c4d90ae3bea035df4546f"
          ]
        }
      },
      "source": [
        "import cv2\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import IterableDataset\n",
        "from torchvision import models, datasets, transforms\n",
        "from PIL import Image\n",
        "import csv\n",
        "\n",
        "class VideoDataset(IterableDataset):\n",
        "    def __init__(self, filename, transform):\n",
        "        super().__init__()\n",
        "        self.transform = transform\n",
        "        self.stream = cv2.VideoCapture(filename)\n",
        "\n",
        "    def read_next_frame(self):\n",
        "        while True:\n",
        "            samples = torch.zeros(0,3,112,112)\n",
        "            for i in range(16):\n",
        "                ret, frame = self.stream.read()\n",
        "                if not ret:\n",
        "                  self.stream.release()\n",
        "                  return None\n",
        "                img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "                im_pil = Image.fromarray(img)\n",
        "                tmp = self.transform(im_pil).unsqueeze(0)\n",
        "                samples = torch.cat((samples,tmp))\n",
        "            samples = samples.permute((1,0,2,3))\n",
        "            yield torch.tensor(samples)\n",
        "\n",
        "    def __iter__(self):\n",
        "        # worker_info = torch.utils.data.get_worker_info()\n",
        "        # assert worker_info is None:  # single-process data loading, return the full iterator\n",
        "        return self.read_next_frame()\n",
        "\n",
        "\n",
        "labels = read_labels()\n",
        "\n",
        "resnet18_3d = models.video.r3d_18(pretrained=True)\n",
        "resnet18_3d.cuda()\n",
        "resnet18_3d.eval()\n",
        "\n",
        "# https://pytorch.org/docs/stable/torchvision/models.html#video-classification\n",
        "# ... models expect input images normalized in the same way, i.e. mini-batches of 3-channel RGB videos of shape \n",
        "#(3 x T x H x W),\n",
        "# where H and W are expected to be 112, and T is a number of video frames in a clip.\n",
        "# The images have to be loaded in to a range of [0, 1] and then normalized using mean = [0.43216, 0.394666, 0.37645] \n",
        "# and std = [0.22803, 0.22145, 0.216989].\n",
        "\n",
        "transform = transforms.Compose([\n",
        "                                transforms.Resize((112,112)),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize([0.43216, 0.394666, 0.37645], [0.22803, 0.22145, 0.216989])])\n",
        "\n",
        "vd = VideoDataset('video.mp4', transform)\n",
        "dataloader = DataLoader(vd)\n",
        "subtitles = {}\n",
        "packet_size = 16\n",
        "i = 0\n",
        "conf_threshold = 0.45\n",
        "for batch in dataloader:\n",
        "  if batch is None:\n",
        "    break\n",
        "  with torch.no_grad():\n",
        "    result = resnet18_3d(batch.cuda())\n",
        "    sm = torch.nn.Softmax(dim = 1) # 0 - is batch size\n",
        "    result = sm(result)\n",
        "    score, id = result.max(1)\n",
        "    print(labels[int(id.detach().item())], score.item())\n",
        "    if score > conf_threshold: # Use only predictions with confidence above threshold\n",
        "      subtitles[i*packet_size] = \"{} {:.2f}\".format(labels[int(id.item())],score.detach().item())\n",
        "    else:\n",
        "      subtitles[i*packet_size] = \"\"\n",
        "    i += 1\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "id;name\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/r3d_18-b3b3357e.pth\" to /root/.cache/torch/checkpoints/r3d_18-b3b3357e.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee8cf44aa4d041009158b4922c3efd04",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=133546016), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "hammer throw 0.06372684240341187\n",
            "tai chi 0.38046014308929443\n",
            "tai chi 0.3615225851535797\n",
            "tai chi 0.3678002953529358\n",
            "tai chi 0.40854644775390625\n",
            "tai chi 0.3730301856994629\n",
            "tai chi 0.4090980887413025\n",
            "tai chi 0.38700437545776367\n",
            "tai chi 0.37682491540908813\n",
            "tai chi 0.19246824085712433\n",
            "dancing ballet 0.08317755162715912\n",
            "golf driving 0.3107621669769287\n",
            "bowling 0.28593742847442627\n",
            "bowling 0.3495776355266571\n",
            "bowling 0.19746829569339752\n",
            "diving cliff 0.07870832830667496\n",
            "parkour 0.31560102105140686\n",
            "driving tractor 0.4786298871040344\n",
            "disc golfing 0.12461186945438385\n",
            "parkour 0.50790935754776\n",
            "playing saxophone 0.22070284187793732\n",
            "waiting in line 0.3357901871204376\n",
            "busking 0.24348442256450653\n",
            "giving or receiving award 0.6048723459243774\n",
            "giving or receiving award 0.8831714391708374\n",
            "giving or receiving award 0.2689860761165619\n",
            "slapping 0.1498323380947113\n",
            "reading newspaper 0.21372276544570923\n",
            "texting 0.49530866742134094\n",
            "texting 0.34102845191955566\n",
            "busking 0.6346886157989502\n",
            "busking 0.4868960976600647\n",
            "riding unicycle 0.5311412811279297\n",
            "pushing wheelchair 0.695784866809845\n",
            "walking the dog 0.3598858416080475\n",
            "blowing leaves 0.30960866808891296\n",
            "jogging 0.36462029814720154\n",
            "brushing hair 0.2287832498550415\n",
            "washing feet 0.13078173995018005\n",
            "playing chess 0.6911105513572693\n",
            "playing chess 0.46384525299072266\n",
            "shaking hands 0.4752364754676819\n",
            "slapping 0.47051486372947693\n",
            "slapping 0.3579361140727997\n",
            "cleaning windows 0.4657590389251709\n",
            "chopping wood 0.24881944060325623\n",
            "digging 0.5108729600906372\n",
            "chopping wood 0.25614210963249207\n",
            "chopping wood 0.772440493106842\n",
            "chopping wood 0.7622487545013428\n",
            "smoking 0.2175981104373932\n",
            "fixing hair 0.7139000296592712\n",
            "fixing hair 0.7807315587997437\n",
            "texting 0.21859966218471527\n",
            "driving car 0.21974964439868927\n",
            "dining 0.2977769076824188\n",
            "clapping 0.16244454681873322\n",
            "clapping 0.16270798444747925\n",
            "reading newspaper 0.10188561677932739\n",
            "using computer 0.14843353629112244\n",
            "shaking hands 0.30342546105384827\n",
            "kissing 0.408019095659256\n",
            "slapping 0.2550792992115021\n",
            "smoking 0.4072119891643524\n",
            "smoking 0.5062925815582275\n",
            "smoking 0.2599981129169464\n",
            "smoking 0.328189492225647\n",
            "smoking 0.2413494735956192\n",
            "smoking 0.49284300208091736\n",
            "reading book 0.5174036622047424\n",
            "smoking 0.2638055980205536\n",
            "giving or receiving award 0.429526150226593\n",
            "giving or receiving award 0.39379745721817017\n",
            "giving or receiving award 0.41386139392852783\n",
            "giving or receiving award 0.4179549217224121\n",
            "giving or receiving award 0.37940067052841187\n",
            "giving or receiving award 0.4924636483192444\n",
            "giving or receiving award 0.6695364713668823\n",
            "smoking 0.3752531111240387\n",
            "smoking 0.8177186250686646\n",
            "smoking 0.6512977480888367\n",
            "tying knot (not on a tie) 0.03735148161649704\n",
            "tying tie 0.2554186284542084\n",
            "washing hands 0.4090023934841156\n",
            "washing hands 0.22770753502845764\n",
            "giving or receiving award 0.8029172420501709\n",
            "giving or receiving award 0.8311282396316528\n",
            "giving or receiving award 0.8454244136810303\n",
            "smoking hookah 0.8798109889030457\n",
            "smoking hookah 0.21602044999599457\n",
            "playing ukulele 0.3256007730960846\n",
            "texting 0.30851492285728455\n",
            "applauding 0.14564837515354156\n",
            "giving or receiving award 0.12304259091615677\n",
            "smoking 0.22229203581809998\n",
            "smoking 0.28621527552604675\n",
            "smoking 0.2732033133506775\n",
            "smoking 0.749610185623169\n",
            "smoking 0.8725301027297974\n",
            "smoking 0.9708102345466614\n",
            "smoking 0.3395122289657593\n",
            "smoking 0.31437763571739197\n",
            "smoking 0.4166628420352936\n",
            "smoking 0.4633064568042755\n",
            "smoking 0.7731600999832153\n",
            "ice fishing 0.3946157693862915\n",
            "playing ukulele 0.262655645608902\n",
            "smoking 0.525606632232666\n",
            "answering questions 0.2750488221645355\n",
            "dining 0.06697597354650497\n",
            "contact juggling 0.4515298902988434\n",
            "contact juggling 0.17888879776000977\n",
            "playing organ 0.1521722674369812\n",
            "giving or receiving award 0.1418752521276474\n",
            "beatboxing 0.26887086033821106\n",
            "tasting beer 0.1335052102804184\n",
            "tasting beer 0.14413832128047943\n",
            "slapping 0.5778102874755859\n",
            "smoking 0.19689859449863434\n",
            "contact juggling 0.10810767114162445\n",
            "giving or receiving award 0.36769330501556396\n",
            "giving or receiving award 0.3583521544933319\n",
            "playing trumpet 0.13658732175827026\n",
            "driving car 0.25812214612960815\n",
            "extinguishing fire 0.19337564706802368\n",
            "driving car 0.1338072419166565\n",
            "driving car 0.23520858585834503\n",
            "running on treadmill 0.1762421578168869\n",
            "slapping 0.24328692257404327\n",
            "drinking beer 0.22032347321510315\n",
            "robot dancing 0.1612306386232376\n",
            "robot dancing 0.31986314058303833\n",
            "waiting in line 0.17672906816005707\n",
            "ice skating 0.448976069688797\n",
            "cheerleading 0.2631460428237915\n",
            "bartending 0.21720117330551147\n",
            "setting table 0.2213706076145172\n",
            "dining 0.6855127215385437\n",
            "dining 0.3113442659378052\n",
            "dining 0.32890933752059937\n",
            "dining 0.5415241718292236\n",
            "dining 0.23573490977287292\n",
            "dining 0.22955846786499023\n",
            "contact juggling 0.23578770458698273\n",
            "tango dancing 0.9599242210388184\n",
            "hugging 0.33211570978164673\n",
            "hugging 0.49950867891311646\n",
            "tango dancing 0.757210373878479\n",
            "salsa dancing 0.5251085758209229\n",
            "contact juggling 0.4116104543209076\n",
            "tango dancing 0.19205442070960999\n",
            "crying 0.4243682324886322\n",
            "crying 0.3229248821735382\n",
            "tasting beer 0.1803215593099594\n",
            "playing bagpipes 0.8720075488090515\n",
            "playing bagpipes 0.9202338457107544\n",
            "baking cookies 0.2538338005542755\n",
            "texting 0.4839412271976471\n",
            "texting 0.48509499430656433\n",
            "applauding 0.19214190542697906\n",
            "dining 0.9375701546669006\n",
            "dining 0.9531204104423523\n",
            "dining 0.7110500931739807\n",
            "dining 0.31997787952423096\n",
            "dining 0.6735296845436096\n",
            "dining 0.6668572425842285\n",
            "dining 0.48199254274368286\n",
            "parkour 0.030930299311876297\n",
            "parkour 0.03796723112463951\n",
            "dining 0.4643005430698395\n",
            "dining 0.9183419346809387\n",
            "dining 0.878762423992157\n",
            "applauding 0.4638390839099884\n",
            "applauding 0.60833340883255\n",
            "applauding 0.6002722978591919\n",
            "applauding 0.7619926333427429\n",
            "applauding 0.5475595593452454\n",
            "applauding 0.2922497093677521\n",
            "applauding 0.4075257480144501\n",
            "contact juggling 0.6339443922042847\n",
            "dining 0.24059611558914185\n",
            "milking cow 0.2929239571094513\n",
            "using computer 0.8133223056793213\n",
            "stretching arm 0.6149234771728516\n",
            "drop kicking 0.19681422412395477\n",
            "dancing charleston 0.2309376299381256\n",
            "finger snapping 0.16691626608371735\n",
            "tying tie 0.18317264318466187\n",
            "tasting beer 0.059509456157684326\n",
            "marching 0.38002681732177734\n",
            "busking 0.14706499874591827\n",
            "rock scissors paper 0.20719307661056519\n",
            "contact juggling 0.23889048397541046\n",
            "unloading truck 0.23179927468299866\n",
            "driving car 0.9304343461990356\n",
            "tango dancing 0.8957939743995667\n",
            "applauding 0.4237053692340851\n",
            "situp 0.1009882390499115\n",
            "vault 0.21457888185977936\n",
            "singing 0.10174104571342468\n",
            "giving or receiving award 0.16214865446090698\n",
            "tying tie 0.55218106508255\n",
            "tasting beer 0.15902107954025269\n",
            "dining 0.670515775680542\n",
            "giving or receiving award 0.19541828334331512\n",
            "giving or receiving award 0.4526105523109436\n",
            "kissing 0.3429991900920868\n",
            "swing dancing 0.24512098729610443\n",
            "swing dancing 0.3733227849006653\n",
            "giving or receiving award 0.36097586154937744\n",
            "situp 0.132494255900383\n",
            "giving or receiving award 0.21332983672618866\n",
            "tossing coin 0.12371696531772614\n",
            "finger snapping 0.21734219789505005\n",
            "finger snapping 0.1782878339290619\n",
            "finger snapping 0.25533416867256165\n",
            "dining 0.22863014042377472\n",
            "dining 0.41090208292007446\n",
            "testifying 0.32826346158981323\n",
            "applauding 0.4133501946926117\n",
            "testifying 0.32647398114204407\n",
            "applauding 0.6873622536659241\n",
            "applauding 0.759122908115387\n",
            "applauding 0.5940945744514465\n",
            "singing 0.17926932871341705\n",
            "parkour 0.035970721393823624\n",
            "dining 0.1684497594833374\n",
            "dining 0.20288994908332825\n",
            "applauding 0.34561535716056824\n",
            "applauding 0.2873941957950592\n",
            "dining 0.10130229592323303\n",
            "barbequing 0.050072766840457916\n",
            "barbequing 0.05084424093365669\n",
            "barbequing 0.04886852204799652\n",
            "barbequing 0.05795985832810402\n",
            "recording music 0.08887569606304169\n",
            "dancing ballet 0.08948830515146255\n",
            "dancing ballet 0.0898270532488823\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQZKg6ACtVGs",
        "colab_type": "code",
        "outputId": "7c507580-85fd-4d00-bdc2-6eab658cda64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(subtitles)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: '', 16: '', 32: '', 48: '', 64: '', 80: '', 96: '', 112: '', 128: '', 144: '', 160: '', 176: '', 192: '', 208: '', 224: '', 240: '', 256: '', 272: 'driving tractor 0.48', 288: '', 304: 'parkour 0.51', 320: '', 336: '', 352: '', 368: 'giving or receiving award 0.60', 384: 'giving or receiving award 0.88', 400: '', 416: '', 432: '', 448: 'texting 0.50', 464: '', 480: 'busking 0.63', 496: 'busking 0.49', 512: 'riding unicycle 0.53', 528: 'pushing wheelchair 0.70', 544: '', 560: '', 576: '', 592: '', 608: '', 624: 'playing chess 0.69', 640: 'playing chess 0.46', 656: 'shaking hands 0.48', 672: 'slapping 0.47', 688: '', 704: 'cleaning windows 0.47', 720: '', 736: 'digging 0.51', 752: '', 768: 'chopping wood 0.77', 784: 'chopping wood 0.76', 800: '', 816: 'fixing hair 0.71', 832: 'fixing hair 0.78', 848: '', 864: '', 880: '', 896: '', 912: '', 928: '', 944: '', 960: '', 976: '', 992: '', 1008: '', 1024: 'smoking 0.51', 1040: '', 1056: '', 1072: '', 1088: 'smoking 0.49', 1104: 'reading book 0.52', 1120: '', 1136: '', 1152: '', 1168: '', 1184: '', 1200: '', 1216: 'giving or receiving award 0.49', 1232: 'giving or receiving award 0.67', 1248: '', 1264: 'smoking 0.82', 1280: 'smoking 0.65', 1296: '', 1312: '', 1328: '', 1344: '', 1360: 'giving or receiving award 0.80', 1376: 'giving or receiving award 0.83', 1392: 'giving or receiving award 0.85', 1408: 'smoking hookah 0.88', 1424: '', 1440: '', 1456: '', 1472: '', 1488: '', 1504: '', 1520: '', 1536: '', 1552: 'smoking 0.75', 1568: 'smoking 0.87', 1584: 'smoking 0.97', 1600: '', 1616: '', 1632: '', 1648: 'smoking 0.46', 1664: 'smoking 0.77', 1680: '', 1696: '', 1712: 'smoking 0.53', 1728: '', 1744: '', 1760: 'contact juggling 0.45', 1776: '', 1792: '', 1808: '', 1824: '', 1840: '', 1856: '', 1872: 'slapping 0.58', 1888: '', 1904: '', 1920: '', 1936: '', 1952: '', 1968: '', 1984: '', 2000: '', 2016: '', 2032: '', 2048: '', 2064: '', 2080: '', 2096: '', 2112: '', 2128: '', 2144: '', 2160: '', 2176: '', 2192: 'dining 0.69', 2208: '', 2224: '', 2240: 'dining 0.54', 2256: '', 2272: '', 2288: '', 2304: 'tango dancing 0.96', 2320: '', 2336: 'hugging 0.50', 2352: 'tango dancing 0.76', 2368: 'salsa dancing 0.53', 2384: '', 2400: '', 2416: '', 2432: '', 2448: '', 2464: 'playing bagpipes 0.87', 2480: 'playing bagpipes 0.92', 2496: '', 2512: 'texting 0.48', 2528: 'texting 0.49', 2544: '', 2560: 'dining 0.94', 2576: 'dining 0.95', 2592: 'dining 0.71', 2608: '', 2624: 'dining 0.67', 2640: 'dining 0.67', 2656: 'dining 0.48', 2672: '', 2688: '', 2704: 'dining 0.46', 2720: 'dining 0.92', 2736: 'dining 0.88', 2752: 'applauding 0.46', 2768: 'applauding 0.61', 2784: 'applauding 0.60', 2800: 'applauding 0.76', 2816: 'applauding 0.55', 2832: '', 2848: '', 2864: 'contact juggling 0.63', 2880: '', 2896: '', 2912: 'using computer 0.81', 2928: 'stretching arm 0.61', 2944: '', 2960: '', 2976: '', 2992: '', 3008: '', 3024: '', 3040: '', 3056: '', 3072: '', 3088: '', 3104: 'driving car 0.93', 3120: 'tango dancing 0.90', 3136: '', 3152: '', 3168: '', 3184: '', 3200: '', 3216: 'tying tie 0.55', 3232: '', 3248: 'dining 0.67', 3264: '', 3280: 'giving or receiving award 0.45', 3296: '', 3312: '', 3328: '', 3344: '', 3360: '', 3376: '', 3392: '', 3408: '', 3424: '', 3440: '', 3456: '', 3472: '', 3488: '', 3504: '', 3520: '', 3536: 'applauding 0.69', 3552: 'applauding 0.76', 3568: 'applauding 0.59', 3584: '', 3600: '', 3616: '', 3632: '', 3648: '', 3664: '', 3680: '', 3696: '', 3712: '', 3728: '', 3744: '', 3760: '', 3776: '', 3792: ''}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcHczldzo1NO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Write predictions to video as subtitles\n",
        "stream = cv2.VideoCapture(\"video.mp4\")\n",
        "fps = stream.get(cv2.CAP_PROP_FPS)\n",
        "width  = int(stream.get(cv2.CAP_PROP_FRAME_WIDTH))   \n",
        "height = int(stream.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter('output.mp4',fourcc,fps, (width,height))\n",
        "frame_num = 0\n",
        "current_label =\"\"\n",
        "while stream.isOpened():\n",
        "   ret, frame = stream.read() \n",
        "   current_label = subtitles.get(frame_num,current_label)\n",
        "   if ret:\n",
        "     frame = cv2.putText(frame, current_label, (20,300), cv2.FONT_HERSHEY_SIMPLEX , 1, (255,0,0), 3, cv2.LINE_AA) \n",
        "     out.write(frame)\n",
        "   else:\n",
        "     break\n",
        "   frame_num += 1\n",
        "   if not frame_num % 250:\n",
        "     print (\"Writed frame\",frame_num)\n",
        "  \n",
        "stream.release()\n",
        "out.release()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}